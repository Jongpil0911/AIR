{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jongpil0911/AIR/blob/main/exe02a_image_recognition_dog_vs_cat_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fh18eiC7xR67"
      },
      "source": [
        "# 画像認識特論2025（Advanced Image Recognition 2025）"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD8pSGkiAI5i"
      },
      "source": [
        "# \\#2a：犬と猫の画像分類１（Dogs vs Cats 1）\n",
        "\n",
        "---\n",
        "Kaggleで実施された犬か猫かを見分ける画像分類問題に取り組む。ここでは、深層学習ではなく、古典的な人手で特徴量を設計して機械学習により分類する問題に取り組む。\n",
        "\n",
        "Study on the image classification problem of distinguishing between a dog or a cat conducted on Kaggle. Here, we tackle the problem of classifying by machine learning, with features designed by hand in the classical way (hand-craft approach), rather than by deep learning.\n",
        "\n",
        "<br>\n",
        "\n",
        "Kaggleは、一言でいうと「機械学習のコンペティションサービス」である。\n",
        "\n",
        "In a nutshell, Kaggle is a machine learning competition service.\n",
        "\n",
        "<br>\n",
        "\n",
        "本演習で利用するデータは、下記 Kaggleのサイトからダウンロードできる。しかし、アカウント登録が必要であるため、ここでは、Kaggleのサイトで公開されている学習データのみを提供する。データは他者に配布しないこと。\n",
        "\n",
        "The dataset used in this exercise can be downloaded from the Kaggle site below. However, since account registration is required, only training data available on the Kaggle site is provided here. The data should not be distributed to others.\n",
        "\n",
        "- Detail of dataset:\n",
        "https://www.kaggle.com/competitions/dogs-vs-cats/overview\n",
        "\n",
        "<br>\n",
        "\n",
        "- ランタイムのタイプ: Python 3\n",
        "- ハードウェア アクセラレータ: CPU\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Feuy7sa_7t8u"
      },
      "source": [
        "Write your student number and name.\n",
        "\n",
        "- <font color= \"blue\">学生番号（Student number）</font> :\n",
        "- <font color= \"blue\">氏名（Name）</font> :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "### 2a-1. Google Driveのマウント\n",
        "\n",
        "Mount Google Drive.\n",
        "\n",
        "Google Colab無償版は以下の利用制限がある。今回利用するデータセットは、データ容量が約600MBであり、利用制限は超えていないものの実施するたびにデータをアップロードすることは手間である。そこで、Google Driveにデータをアップロードし、Google ColabよりGoogle Driveをマウントすることで手間を軽減する。<br>\n",
        "\n",
        "The free version of Google Colab has the following usage restrictions. The dataset used in this study is approximately 600MB in size, and although it does not exceed the usage limit, uploading the data each time it is used would be time-consuming. Therefore, we will upload the data to Google Drive and mount Google Drive from Google Colab to reduce the time and effort.\n",
        "\n",
        "* RAM：12GB<br>\n",
        "\n",
        "* ディスク（storage）：CPU/TPC: max 107GB、GPU: max 68GB\n",
        "\n",
        "* 90分ルール：何も操作せずに90分経つとリセット<br>\n",
        "Idle cut-off 90 minutes\n",
        "\n",
        "* 12時間ルール：インスタンスが起動してから12時間経つとリセット<br>\n",
        "Limit 12 hours max per session"
      ],
      "metadata": {
        "id": "pEMZZU_WqvAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "K6HO1-bOpn3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a-2. データ準備\n",
        "\n",
        "Data preparation\n",
        "\n",
        "下記よりデータをダウンロードして、各自のGoogleドライブにアップロードする。zipファイルをそのままアップロードする場合は、以下の処理を1回だけ実行する。zipファイルではなく、解凍したフォルダをGoogleドライブへアップロードする場合は、以下の処理は実行しなくて良い。\n",
        "\n",
        "Download the data from the following links and upload the data to your Google Drive. If you upload the zip file, execute the following process only once. If you upload the unzipped folder to Google Drive, you do not need to execute the following process.\n",
        "\n",
        "* train.zip (543.2MB) <br>\n",
        "[download](https://drive.google.com/file/d/12gP23qXYenKSPvoWbnuBC_vGeWq4YFAN/view?usp=sharing)\n",
        "\n",
        "<br>\n",
        "\n",
        "パスは各自の設定に合わせて変更する。\n",
        "\n",
        "The path should be changed according to their own settings."
      ],
      "metadata": {
        "id": "nicpDl4G6blZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks/AIR2025/dogs-vs-cats/\n",
        "\n",
        "# zipファイルの解凍\n",
        "!unzip train.zip"
      ],
      "metadata": {
        "id": "XvBrDARHqQgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a-3. インストール\n",
        "\n",
        "Install\n",
        "\n",
        "* imutilsモジュール：OpenCVによる画像処理ユーティリティモジュール<br>\n",
        "A series of convenience functions to make basic image processing functions such as translation, rotation, resizing, skeletonization, displaying Matplotlib images, sorting contours, detecting edges, and much more easier with OpenCV and both Python 2.7 and Python 3."
      ],
      "metadata": {
        "id": "iLC0KTQCDxR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imutils"
      ],
      "metadata": {
        "id": "4f9FXJJZoqeH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a-4. ライブラリのインポート\n",
        "\n",
        "Import libraries"
      ],
      "metadata": {
        "id": "uAp8IaW8qm3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from skimage.feature import local_binary_pattern\n",
        "\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "YdRMgIYoon2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a-5. 関数定義\n",
        "\n",
        "Function definition"
      ],
      "metadata": {
        "id": "JEEiEQcVt-gb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 画像サイズを 32x32[pixel]（=1024）にリサイズし、1024個の画素値を特徴量として利用する。\n",
        "# Resize the image to a fixed size, then flatten the image into a list of raw pixel intensities\n",
        "# 特徴量数: 1024\n",
        "def image_to_feature_vector(image, size=(32, 32)):\n",
        "  return cv2.resize(image, size).flatten()\n",
        "\n",
        "# RGB色空間からHSV色空間に変換し、HSV色空間の正規化ヒストグラムを求めて特徴量とする。\n",
        "# Extract a 3D color histogram from the HSV color space using the supplied number of `bins` per channel\n",
        "# 特徴量数: 692 = 180 + 256 + 256\n",
        "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
        "\t# RGB --> HSV\n",
        "\thsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "\thist = cv2.calcHist([hsv], [0, 1, 2], None, bins,\t[0, 180, 0, 256, 0, 256])\n",
        "\n",
        "\tif imutils.is_cv2():\n",
        "\t\thist = cv2.normalize(hist)\n",
        "\telse:\n",
        "\t\tcv2.normalize(hist, hist)\n",
        "\n",
        "\treturn hist.flatten()\n",
        "\n",
        "# LBPヒストグラムを求めて特徴量とする。\n",
        "# Extract a LBP histogram.\n",
        "def extract_LBP_histogram(image):\n",
        "\tnum_points = 24\n",
        "\tradius = 8\n",
        "\n",
        "\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\t# compute the Local Binary Pattern representation\n",
        "\t# of the image, and then use the LBP representation\n",
        "\t# to build the histogram of patterns\n",
        "\tlbp = local_binary_pattern(gray, num_points,\tradius, method=\"uniform\")\n",
        "\t(hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, num_points+ 3), range=(0, num_points + 2))\n",
        "\t# normalize the histogram\n",
        "\thist = hist.astype(\"float\")\n",
        "\thist /= (hist.sum() + 1e-7)\n",
        "\n",
        "\t# return the histogram of Local Binary Patterns\n",
        "\treturn hist"
      ],
      "metadata": {
        "id": "0mjtYwtEo5QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a-6. 画像データおよび特徴量の確認\n",
        "\n",
        "Check of image data and features\n",
        "\n",
        "<br>\n",
        "\n",
        "画像データのパスは各自の設定に合わせて変更する。\n",
        "\n",
        "The path of the image data should be changed according to their own settings."
      ],
      "metadata": {
        "id": "bD8QDy79YyMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir_name = \"/content/drive/MyDrive/ColabNotebooks/AIR2025/dogs-vs-cats/train/\"\n",
        "\n",
        "image_paths = list(paths.list_images(dir_name))\n",
        "\n",
        "print(image_paths)\n",
        "\n",
        "image_path = image_paths[0]\n",
        "print(image_path)\n",
        "\n",
        "# load a sample image\n",
        "image = cv2.imread(image_path)\n",
        "\n",
        "# show a loaded image\n",
        "cv2_imshow(image)\n",
        "\n",
        "# extract a color histogram\n",
        "hist = extract_color_histogram(image)\n",
        "\n",
        "# extract a LBP histogram\n",
        "lbp = extract_LBP_histogram(image)\n",
        "\n",
        "# show the color histogram\n",
        "data_num = len(hist)\n",
        "hist_x = np.linspace(1, data_num, data_num)\n",
        "\n",
        "print(data_num)\n",
        "\n",
        "fig = plt.figure(figsize=[10, 5])\n",
        "plt.grid()\n",
        "plt.bar(hist_x, hist)\n",
        "plt.xlim(0, data_num)\n",
        "plt.xticks(np.arange(0, data_num+1, 32))\n",
        "plt.show()\n",
        "\n",
        "# show the LBP histogram\n",
        "data_num = len(lbp)\n",
        "lbp_x = np.linspace(1, data_num, data_num)\n",
        "\n",
        "print(data_num)\n",
        "\n",
        "fig = plt.figure(figsize=[10, 5])\n",
        "plt.grid(False)\n",
        "plt.bar(lbp_x, lbp)\n",
        "plt.xlim(0, data_num+1)\n",
        "plt.xticks(np.arange(1, data_num+1, 1))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v8Pmvx4cM0Ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a-7. 画像データの読み込み\n",
        "\n",
        "Load image data\n",
        "\n",
        "<br>\n",
        "\n",
        "処理時間は約50分\n",
        "\n",
        "Processing time is approximately 50 minutes."
      ],
      "metadata": {
        "id": "zxpp3wSSrA3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# grab the list of images that we'll be describing\n",
        "print(\"[INFO] describing images...\")\n",
        "dir_name = \"/content/drive/MyDrive/ColabNotebooks/AIR2025/dogs-vs-cats/train/\"\n",
        "\n",
        "image_paths = list(paths.list_images(dir_name))\n",
        "\n",
        "# initialize the raw pixel intensities matrix, the features matrix,\n",
        "# and labels list\n",
        "raw_images = []\n",
        "hist_features = []\n",
        "lbp_features = []\n",
        "labels = []\n",
        "\n",
        "# loop over the input images\n",
        "for (i, image_path) in enumerate(image_paths):\n",
        "\t#\tprint(image_path)\n",
        "\t# load the image and extract the class label (assuming that our\n",
        "\t# path as the format: /path/to/dataset/{class}.{image_num}.jpg\n",
        "\timage = cv2.imread(image_path)\n",
        "\tlabel = image_path.split(os.path.sep)[-1].split(\".\")[0]\n",
        "\n",
        "\t# extract raw pixel intensity \"features\", followed by a color\n",
        "\t# histogram to characterize the color distribution of the pixels\n",
        "\t# in the image\n",
        "\tpixels = image_to_feature_vector(image)\n",
        "\thist = extract_color_histogram(image)\n",
        "\tlbp = extract_LBP_histogram(image)\n",
        "\n",
        "\t# update the raw images, features, and labels matricies,\n",
        "\t# respectively\n",
        "\traw_images.append(pixels)\n",
        "\thist_features.append(hist)\n",
        "\tlbp_features.append(lbp)\n",
        "\tlabels.append(label)\n",
        "\n",
        "\t# show an update every 1,000 images\n",
        "\tif i > 0 and i % 1000 == 0:\n",
        "\t\tprint(\"[INFO] processed {}/{}\".format(i, len(image_paths)))\n",
        "\n",
        "# show some information on the memory consumed by the raw images\n",
        "# matrix and features matrix\n",
        "raw_images = np.array(raw_images)\n",
        "hist_features = np.array(hist_features)\n",
        "lbp_features = np.array(lbp_features)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"[INFO] pixels matrix: {:.2f}MB\".format(raw_images.nbytes / (1024 * 1000.0)))\n",
        "print(\"[INFO] hist features matrix: {:.2f}MB\".format(hist_features.nbytes / (1024 * 1000.0)))\n",
        "print(\"[INFO] lbp features matrix: {:.2f}MB\".format(lbp_features.nbytes / (1024 * 1000.0)))\n",
        "\n",
        "# データの分割\n",
        "# partition the data into training and testing splits, using 75%\n",
        "# of the data for training and the remaining 25% for testing\n",
        "(train_raw_images, test_raw_images, train_raw_labels, test_raw_labels) = train_test_split(raw_images, labels, test_size=0.25, random_state=42)\n",
        "(train_hist_features, test_hist_features, train_hist_features_labels, test_hist_features_labels) = train_test_split(hist_features, labels, test_size=0.25, random_state=42)\n",
        "(train_lbp_features, test_lbp_features, train_lbp_features_labels, test_lbp_features_labels) = train_test_split(lbp_features, labels, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "G5AXKb78pCgh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a-8. 学習＋認識処理\n",
        "\n",
        "Training and recognition"
      ],
      "metadata": {
        "id": "0xymsUgqVy6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 集計用\n",
        "scores = {}"
      ],
      "metadata": {
        "id": "YilyRSKBWCLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] evaluating raw pixel accuracy...\")\n",
        "model = KNeighborsClassifier(n_neighbors=1, n_jobs=-1)\n",
        "model.fit(train_raw_images, train_raw_labels)\n",
        "acc_train = model.score(train_raw_images, train_raw_labels)\n",
        "acc_test = model.score(test_raw_images, test_raw_labels)\n",
        "print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc_train * 100))\n",
        "print(\"[INFO] raw pixel accuracy: {:.2f}%\".format(acc_test * 100))\n",
        "\n",
        "scores[(\"1. raw pixel\", \"(a) train_accuracy\")] = acc_train\n",
        "scores[(\"1. raw pixel\", \"(b) test_accuracy\")] = acc_test"
      ],
      "metadata": {
        "id": "uaD40gXV6hp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] evaluating histogram accuracy...\")\n",
        "model = KNeighborsClassifier(n_neighbors=1,\tn_jobs=-1)\n",
        "model.fit(train_hist_features, train_hist_features_labels)\n",
        "acc_train = model.score(train_hist_features, train_hist_features_labels)\n",
        "acc_test = model.score(test_hist_features, test_hist_features_labels)\n",
        "print(\"[INFO] histogram accuracy: {:.2f}%\".format(acc_train * 100))\n",
        "print(\"[INFO] histogram accuracy: {:.2f}%\".format(acc_test * 100))\n",
        "\n",
        "scores[(\"2. HSV histogram\", \"(a) train_accuracy\")] = acc_train\n",
        "scores[(\"2. HSV histogram\", \"(b) test_accuracy\")] = acc_test"
      ],
      "metadata": {
        "id": "ZEgH4GwH3gJm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] evaluating LBP accuracy...\")\n",
        "model = KNeighborsClassifier(n_neighbors=1,\tn_jobs=-1)\n",
        "model.fit(train_lbp_features, train_lbp_features_labels)\n",
        "acc_train = model.score(train_lbp_features, train_lbp_features_labels)\n",
        "acc_test = model.score(test_lbp_features, test_lbp_features_labels)\n",
        "print(\"[INFO] LBP accuracy: {:.2f}%\".format(acc_train * 100))\n",
        "print(\"[INFO] LBP accuracy: {:.2f}%\".format(acc_test * 100))\n",
        "\n",
        "scores[(\"3. LBP\", \"(a) train_accuracy\")] = acc_train\n",
        "scores[(\"3. LBP\", \"(b) test_accuracy\")] = acc_test"
      ],
      "metadata": {
        "id": "sSP2tWgb7gor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2a-9. 実験結果の集計\n",
        "\n",
        "Summary experimental results."
      ],
      "metadata": {
        "id": "BnoRWz4SXzBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(scores).unstack()"
      ],
      "metadata": {
        "id": "72WhaUvLWlYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## <font color= \"blue\">課題（Report）</font>\n",
        "\n",
        "画素値、HSVカラーヒストグラム、LBPヒストグラムの三つの特徴量を用いた。各自で他の特徴量を計算するコードを実装し、四つの特徴量を用いた比較実験を実施しなさい。\n",
        "\n",
        "Three features were used: pixel value, HSV color histogram, and LBP histogram. Implement a code to calculate the other features on your own, and conduct a comparison experiment using the four features.\n",
        "\n",
        "<br>\n",
        "\n",
        "実験結果について、日本語または英語で説明しなさい。\n",
        "\n",
        "Discuss the experimental results in Japanese or English..\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_0FuaJEvbdvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Report #2a\n",
        "\n",
        "After completing all the exercises, save the notebook (ipynb) and submit it to Moodle as Report #2a."
      ],
      "metadata": {
        "id": "Ur6Cw4Mwbove"
      }
    }
  ]
}